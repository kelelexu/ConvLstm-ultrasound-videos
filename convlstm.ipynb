{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "\n",
    "\n",
    "class ConvLSTMCell(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, input_dim, hidden_dim, kernel_size, bias):\n",
    "        \"\"\"\n",
    "        Initialize ConvLSTM cell.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        input_size: (int, int)\n",
    "            Height and width of input tensor as (height, width).\n",
    "        input_dim: int\n",
    "            Number of channels of input tensor.\n",
    "        hidden_dim: int\n",
    "            Number of channels of hidden state.\n",
    "        kernel_size: (int, int)\n",
    "            Size of the convolutional kernel.\n",
    "        bias: bool\n",
    "            Whether or not to add the bias.\n",
    "        \"\"\"\n",
    "\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "\n",
    "        self.height, self.width = input_size\n",
    "        self.input_dim  = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding     = kernel_size[0] // 2, kernel_size[1] // 2\n",
    "        self.bias        = bias\n",
    "        \n",
    "        self.conv = nn.Sequential(nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
    "                              out_channels=4 * self.hidden_dim,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding,\n",
    "                              bias=self.bias))\n",
    "\n",
    "    def forward(self, input_tensor, cur_state):\n",
    "        \n",
    "        h_cur, c_cur = cur_state\n",
    "        \n",
    "        combined = torch.cat([input_tensor, h_cur], dim=1)  \n",
    "        \n",
    "        combined_conv = self.conv(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1) \n",
    "        i = torch.sigmoid(cc_i)\n",
    "        f = torch.sigmoid(cc_f)\n",
    "        o = torch.sigmoid(cc_o)\n",
    "        g = torch.tanh(cc_g)\n",
    "\n",
    "        c_next = f * c_cur + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "        \n",
    "        return h_next, c_next\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return (Variable(torch.zeros(batch_size, self.hidden_dim, self.height, self.width)).cuda(),\n",
    "                Variable(torch.zeros(batch_size, self.hidden_dim, self.height, self.width)).cuda())\n",
    "\n",
    "\n",
    "class ConvLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, input_dim, hidden_dim, kernel_size, num_layers,\n",
    "                 batch_first=False, bias=True, return_all_layers=False):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "\n",
    "        self._check_kernel_size_consistency(kernel_size)\n",
    "\n",
    "\n",
    "        kernel_size = self._extend_for_multilayer(kernel_size, num_layers)\n",
    "        hidden_dim  = self._extend_for_multilayer(hidden_dim, num_layers)\n",
    "        if not len(kernel_size) == len(hidden_dim) == num_layers:\n",
    "            raise ValueError('Inconsistent list length.')\n",
    "\n",
    "        self.height, self.width = input_size\n",
    "\n",
    "        self.input_dim  = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first\n",
    "        self.bias = bias\n",
    "        self.return_all_layers = return_all_layers\n",
    "\n",
    "        cell_list = []\n",
    "        for i in range(0, self.num_layers):\n",
    "            cur_input_dim = self.input_dim if i == 0 else self.hidden_dim[i-1]\n",
    "\n",
    "            cell_list.append(ConvLSTMCell(input_size=(self.height, self.width),\n",
    "                                          input_dim=cur_input_dim,\n",
    "                                          hidden_dim=self.hidden_dim[i],\n",
    "                                          kernel_size=self.kernel_size[i],\n",
    "                                          bias=self.bias))\n",
    "\n",
    "        self.cell_list = nn.ModuleList(cell_list)\n",
    "        self.conv2d1=nn.Sequential(nn.Conv2d(hidden_dim[-1],1,3,1,1),\n",
    "#                                   nn.BatchNorm2d(1),\n",
    "                                  nn.ReLU(inplace=True))                                  \n",
    "#         self.conv2d2=nn.Sequential(nn.Conv2d(16,8,3,1,1),\n",
    "#                                    nn.BatchNorm2d(8),\n",
    "#                                   nn.ReLU(inplace=True))  \n",
    "#         self.conv2d3=nn.Sequential(nn.Conv2d(8,1,3,1,1),\n",
    "#                                    nn.BatchNorm2d(1),\n",
    "#                                    nn.ReLU(inplace=True))  \n",
    "#         self.fc=nn.Sequential(nn.Linear(96*96,96*96))\n",
    "\n",
    "    def forward(self, input_tensor, hidden_state=None):\n",
    "        \"\"\"\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        input_tensor: todo \n",
    "            5-D Tensor either of shape (t, b, c, h, w) or (b, t, c, h, w)\n",
    "        hidden_state: todo\n",
    "            None. todo implement stateful\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        last_state_list, layer_output\n",
    "        \"\"\"\n",
    "        if not self.batch_first:\n",
    "\n",
    "            input_tensor.permute(1, 0, 2, 3, 4)\n",
    "\n",
    "\n",
    "        if hidden_state is not None:\n",
    "            raise NotImplementedError()\n",
    "        else:\n",
    "            hidden_state = self._init_hidden(batch_size=input_tensor.size(0))\n",
    "\n",
    "        layer_output_list = []\n",
    "        last_state_list   = []\n",
    "\n",
    "        seq_len = input_tensor.size(1)\n",
    "        cur_layer_input = input_tensor\n",
    "\n",
    "        for layer_idx in range(self.num_layers):\n",
    "\n",
    "            h, c = hidden_state[layer_idx]\n",
    "            output_inner = []\n",
    "            for t in range(seq_len):\n",
    "\n",
    "                h, c = self.cell_list[layer_idx](input_tensor=cur_layer_input[:, t, :, :, :],\n",
    "                                                 cur_state=[h, c])\n",
    "                output_inner.append(h)\n",
    "\n",
    "            layer_output = torch.stack(output_inner, dim=1)\n",
    "            cur_layer_input = layer_output\n",
    "\n",
    "            layer_output_list.append(layer_output)\n",
    "            last_state_list.append([h, c])\n",
    "\n",
    "        if not self.return_all_layers:\n",
    "            layer_output_list = layer_output_list[-1:]\n",
    "            last_state_list   = last_state_list[-1:]\n",
    "        \n",
    "        #myout1=self.conv2d1(last_state_list[-1][-1])\n",
    "        myout1=self.conv2d1(layer_output_list[-1][:,-1,:,:,:])\n",
    "        \n",
    "#         myout2=self.conv2d2(myout1)\n",
    "#         myout3=self.conv2d3(myout2)\n",
    "\n",
    "\n",
    "        return 255*myout1\n",
    "\n",
    "\n",
    "\n",
    "    def _init_hidden(self, batch_size):\n",
    "        init_states = []\n",
    "        for i in range(self.num_layers):\n",
    "            init_states.append(self.cell_list[i].init_hidden(batch_size))\n",
    "        return init_states\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_kernel_size_consistency(kernel_size):\n",
    "        if not (isinstance(kernel_size, tuple) or\n",
    "                    (isinstance(kernel_size, list) and all([isinstance(elem, tuple) for elem in kernel_size]))):\n",
    "            raise ValueError('`kernel_size` must be tuple or list of tuples')\n",
    "\n",
    "    @staticmethod\n",
    "    def _extend_for_multilayer(param, num_layers):\n",
    "        if not isinstance(param, list):\n",
    "            param = [param] * num_layers\n",
    "        return param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#参数\n",
    "height, width=96,96\n",
    "channels=1\n",
    "BATCH_SIZE=16\n",
    "LR=0.001\n",
    "Weight_decay=0e-5\n",
    "Max_epoch=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data=np.load('data.npy')\n",
    "label=np.load('label.npy')\n",
    "\n",
    "test=np.load('test.npy')\n",
    "test_label=np.load('test_label.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=data[0:int(0.8*len(data))]\n",
    "y_train=label[0:int(0.8*len(data))]\n",
    "val=data[int(0.8*len(data)):]\n",
    "y_val=label[int(0.8*len(data)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=torch.Tensor(train).float()\n",
    "y_train=torch.Tensor(y_train).float()\n",
    "val=torch.Tensor(val).float()\n",
    "y_val=torch.Tensor(y_val).float()\n",
    "\n",
    "test=torch.Tensor(test).float()\n",
    "y_test=torch.Tensor(test_label).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as Data\n",
    "train_dataset = Data.TensorDataset(train,y_train)\n",
    "val_dataset = Data.TensorDataset(val,y_val)\n",
    "test_dataset = Data.TensorDataset(test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = Data.DataLoader(\n",
    "    dataset=train_dataset,      \n",
    "    batch_size=BATCH_SIZE,      \n",
    "    shuffle=True,               \n",
    "    num_workers=2,              \n",
    ")\n",
    "val_loader = Data.DataLoader(\n",
    "    dataset=val_dataset,      \n",
    "    batch_size=BATCH_SIZE,     \n",
    "    shuffle=False,            \n",
    "    num_workers=2,           \n",
    "    )\n",
    "test_loader = Data.DataLoader(\n",
    "    dataset=test_dataset,      \n",
    "    batch_size=BATCH_SIZE,     \n",
    "    shuffle=False,            \n",
    "    num_workers=2, \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ConvLSTM(input_size=(height, width),\n",
    "                 input_dim=channels,\n",
    "                 hidden_dim=[64, 64, 32],\n",
    "                 kernel_size=(3, 3),\n",
    "                 num_layers=3,\n",
    "                 batch_first=True,\n",
    "                 bias=True,\n",
    "                 return_all_layers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#目标函数及优化器\n",
    "criterion=nn.MSELoss()\n",
    "lr=LR\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=lr,weight_decay=Weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def val(model,dataloader):\n",
    "    with torch.no_grad():\n",
    "        cv=[]\n",
    "        summ=0\n",
    "        for ii,(data,label) in enumerate(dataloader):\n",
    "            input=Variable(data,volatile=True)\n",
    "            input=input.view(-1,8,1,96,96)\n",
    "            target=Variable(label,volatile=True)\n",
    "            target=target.view(-1,1,96,96)\n",
    "            target=target\n",
    "            input=input.cuda()\n",
    "            input=input/255\n",
    "            target=target.cuda()\n",
    "            score=model(input)\n",
    "            mloss=criterion(score,target)\n",
    "            cv.append(mloss)\n",
    "        summ=0\n",
    "        for t in cv:\n",
    "            summ+=t.data\n",
    "\n",
    "        return summ/len(cv)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(Max_epoch):\n",
    "    for ii,(data,label) in enumerate(train_loader):\n",
    "    \n",
    "        input=Variable(data)\n",
    "        input=input.view(-1,8,1,96,96)\n",
    "        target=Variable(label)\n",
    "        target=target.view(-1,1,96,96)\n",
    "        input=input.cuda()\n",
    "        target=target.cuda()\n",
    "        input=input/255\n",
    "        optimizer.zero_grad()\n",
    "        score=model(input)\n",
    "        loss=criterion(score,target)\n",
    "        if ii%80==0:\n",
    "            print('epoch:',epoch,'train_loss:',loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss_val=val(model,val_loader)\n",
    "    loss_test=val(model,test_loader)\n",
    "    torch.save(model, 'model'+str(loss_test)+'.pkl')\n",
    "    print('val loss:',loss_val,'test loss:',loss_test)   \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
